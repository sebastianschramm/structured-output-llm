{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzKra8lLYsa/jHlcyg4HfP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d8Bnn0Slz38",
        "outputId": "b7d514c4-8d26-4af6-f1bf-5a712a449e5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "outlines==0.0.8\n",
            "pydantic==2.2.0\n",
            "transformers==4.32.0\n"
          ]
        }
      ],
      "source": [
        "!pip install outlines pydantic transformers -q && pip freeze | grep -w \"outlines\\|pydantic\\|transformers\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from enum import Enum\n",
        "from functools import partial\n",
        "from typing import Optional\n",
        "\n",
        "from pydantic import BaseModel\n",
        "\n",
        "from outlines import models\n",
        "from outlines import text\n",
        "from outlines.text import generate"
      ],
      "metadata": {
        "id": "nrk3wDssxUMP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load a small language model\n",
        "\n",
        "model = models.transformers(\"gpt2\")"
      ],
      "metadata": {
        "id": "Tp3RpEtaxcZn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define our expected output structure as pydantic model\n",
        "\n",
        "class Label(str, Enum):\n",
        "  positive = \"positive\"\n",
        "  negative = \"negative\"\n",
        "\n",
        "\n",
        "class Prediction(BaseModel):\n",
        "  prediction: Label"
      ],
      "metadata": {
        "id": "tf08Lj1KxgLe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@text.prompt\n",
        "def get_prompt(instructions: str, input_text: str, json: callable, Prediction, examples: Optional[tuple] = None):\n",
        "  \"\"\"Instructions: {{ instructions }}\n",
        "\n",
        "  {% if examples %}\n",
        "  {% for example in examples %}\n",
        "  Text: {{ example[0] }}\n",
        "  {{ json.dumps(Prediction(prediction=example[1]).model_json_schema()) }}\n",
        "  {% endfor %}\n",
        "  {% endif %}\n",
        "\n",
        "  Text: {{ input_text}}\\n\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "get_prompt = partial(get_prompt, json=json, Prediction=Prediction)"
      ],
      "metadata": {
        "id": "tUq0mQp_yAIC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fix instructions for sentiment classifier prompt template\n",
        "\n",
        "instructions = \"You are a sentiment classifier. Your task is to classify whether the text below has positive or negative sentiment.\"\n",
        "get_sentiment_classifier_prompt = partial(get_prompt, instructions=instructions)"
      ],
      "metadata": {
        "id": "MwsmSS5LA-H5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a few static examples\n",
        "examples = [('... the movie is just a plain old monster . ', 'negative', 'escaping the studio , piccoli is warmly affecting and so is this adroitly minimalist movie . ', 'positive')]"
      ],
      "metadata": {
        "id": "B9qTJ2-m1gC9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run inference without examples\n",
        "\n",
        "input = \"it's a charming and often affecting journey.\"  # true label = \"positive\"\n",
        "\n",
        "prompt = get_sentiment_classifier_prompt(input_text=input)\n",
        "\n",
        "classification = generate.json(model=model, schema=Prediction)(prompt)\n",
        "json.loads(classification)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkN6qIB5xtH2",
        "outputId": "41a8fc5e-6f53-44df-eb85-01822798afb6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prediction': 'positive'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run inference with examples\n",
        "\n",
        "input = \"it's a charming and often affecting journey.\"  # true label = \"positive\"\n",
        "\n",
        "prompt = get_sentiment_classifier_prompt(input_text=input, examples=examples)\n",
        "\n",
        "classification = generate.json(model=model, schema=Prediction)(prompt)\n",
        "json.loads(classification)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpNTCkOR2eSv",
        "outputId": "762a2544-54ec-44d4-d989-2493e9201005"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prediction': 'positive'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run inference with examples on another input text\n",
        "\n",
        "input = \"the movie fails to live up to the sum of its parts . \" # true label = negative\n",
        "\n",
        "prompt = get_sentiment_classifier_prompt(input_text=input, examples=examples)\n",
        "\n",
        "classification = generate.json(model=model, schema=Prediction)(prompt)\n",
        "json.loads(classification)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDutcTeB7c0f",
        "outputId": "76abb5e5-692e-4610-a6cd-b77004855ffc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prediction': 'negative'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IdKKUWOw_MO3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}